<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[My favorite quotes & writings]]></title>
    <url>%2F2018%2F09%2F10%2FMy-favorite-quotes%2F</url>
    <content type="text"><![CDATA[In this post, I exhibit some my preferred quotes or my own writings about life, study, research, etc. life Better safe than sorry. Better late than never. 重剑无锋，大巧不工。 Stay hungry, stay foolish. Stay simple, stay young. :) research Think twice, code once. Research means heuristic search, not exhaustive search. To be continued…]]></content>
      <categories>
        <category>人生经验</category>
      </categories>
      <tags>
        <tag>life</tag>
        <tag>non-technical</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[[Reading notes] Entity Matching with Active Monotone Classification]]></title>
    <url>%2F2018%2F09%2F09%2FReading-notes-Entity-Matching-with-Active-Monotone-Classification%2F</url>
    <content type="text"><![CDATA[This is a single-author work by Prof. Tao Yufei, awarded with PODS 2018 best paper. Prof. Tao gave us a seminar of his outstanding work on this Friday. In this seminar, he introduced (1) what the entity matching problem is; (2) how he formulates entity matching to a multidimensional classification problem; (3) his “small-and-sweet” algorithm to solve this problem and (4) some hints about his theoretical analysis. In this post, we focus on the first 3 points. The entity matching problemSuppose Amazon and ebay place a set of advertisements on their website respectively, we denote this two sets with $A$ and $E$. each advertisement has attributes like prod-name, prod-discription, year, price, and so on. Now we want wo know whether advertisements $x$ and $y$ are about the same product, for all $(x, y) \in A \times E$. Convert entity mathching to a multidimensional classification problemA “small-and-sweet” algorithm to solve the formulated problemMy thoughts The process of problem formulation introduced in this paper is quite instructive. The framework to deal with matching problem can be transferred to many other problems… As the title of the paper implies, it’s an active learning algorithm, which require less labeling job for training set than supervised leanrning, and can be done interactively. However, it’s a monotone classifier, which means there is a trade-off: the algorithm will perform perfectly (zero error) if the data set is strictly monotone, but if the data set has undesired pattern, the classification result can be terrible. An extreme case can be shown as the following picture. In short, it has strong assumption for data, and not stable. If we have enough labeled data, or the labeling job is cheap, we should still choose descision tree or some other classifier. (a naughty spy point dive deeply into its opposite group, and unfortunately be chosen by the algorithm) (give a table of comparison with decision tree and SVM) how to solve the problem in 2? Careful feature engineering? Run several times and do ensemble? or?]]></content>
      <categories>
        <category>学习一个</category>
      </categories>
      <tags>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Daily progress - 20180907]]></title>
    <url>%2F2018%2F09%2F08%2FDaily-progress-20180907%2F</url>
    <content type="text"><![CDATA[Tried to install FlexPS but meet a bunch of errors. Will continue installing next Monday with the help of Yuzhen. Attend a seminar by Prof. Yufei Tao, about his recent PODS best paper Entity Matching with Active Monotone Classification, benefit a lot from it. May give a post about the seminar this weekend. Read a paper, and posted reading notes “https://leifzhu.github.io/2018/09/07/Reading-Notes-Deep-Extraction-of-Manga-Structural-Lines/#more&quot; Some trivial things related to course selection, LOCPG registration, etc.]]></content>
      <categories>
        <category>历史进程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[[Reading Notes] Deep Extraction of Manga Structural Lines]]></title>
    <url>%2F2018%2F09%2F07%2FReading-Notes-Deep-Extraction-of-Manga-Structural-Lines%2F</url>
    <content type="text"><![CDATA[This is a work published on Tansaction on Graphics by Chengze Li et al. It aims to extract structural lines from pattern-rich manga. Its contributions are: (1)Novel CNN frame-work tailored for their extraction task; (2) An ingenious way of “reversely generating” data set, which well solved the requirement of demanding large amount of data by deep learning methods. (3) proposed some potential applications utilizing this work. Purposethe purpose can be intuitively presented by the cover picture of this paper: HighlightsComparison with related worksIn section 2, Related Works, The author classify existing methods to 3 categories (edge detection, texture removal and CNN-based techniques), then compare each catgory method with theirs to distinguish this work, so this part is clear and well-organized. Training data generationIn section 4.1, instead of manually tracing structural lines in screen patterns decorated mangas, they generate data set inversely, i.e. sythesizing screen-rich manga from the screen-free line drawings, by laying a rich library of screen patterns. To allign the real world distribution of patterns, they imposed some heuristic rules. CNN frame-work design In section 4.2, the authors presented the network design. Although it’s composed all by existing layers, they persuasivly illstrated why they design the network in this way why three levels of downsampling: experiments show that increasing levels filters away important structural components and leads to blurry structural lines, decreasing levels cannot filter away textural pattern due to limited receptive field. why use residual network(common sense): it allows direct information propagation between the input and output – easy training, better quality. why use convolutions/convolutions for downsampling/upsampling, instead of standard pooling/unpooling: max-pooling breaks spatial continuity. why use skipping (common sense): information at certain level in the downsampling network can be directly passed to the corresponding layer of upscaling network without compression. why use MSE instead of MAE as regularization: keep the tones of structural lines. Potential applicationsommitted. My thoughts Really no assumption? Does this method work when apply test on a picture with the screen patterns do not emerged in pattern library used to sythsize training data set? Especially I see on page 5, the paper mentions “At first glance, it seems…may not exist in real world.” which implies the sensitivity? Can it outperform GAN-based methods? e.g. pix2pix How to utilize the sparsity. Notice the sparsity (most of the pixels are filled with pure white) of structural line drawings, how can we utilize the property? Maybe an unevenly weighted(larger coefficients on false-positive terms) l2 regularization? Or define a structural MAE with 8-connected region (to avoid losing tone but keep sparse output)? Image to image translation can be regarded as a combination of CV and CG, the downscaling part is CV job, and upscaling part is for CG. Retrospect Some knowlege points Deconvolution (precisely, transposed convolution) Unpooling]]></content>
      <categories>
        <category>学习一个</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
        <tag>CG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用bash脚本监控程序输出并自动执行任务]]></title>
    <url>%2F2018%2F09%2F02%2F%E4%BD%BF%E7%94%A8bash%E8%84%9A%E6%9C%AC%E7%9B%91%E6%8E%A7%E7%A8%8B%E5%BA%8F%E8%BE%93%E5%87%BA%E5%B9%B6%E8%87%AA%E5%8A%A8%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[有时候我们需要执行这样的任务：当程序执行到一定的条件时就杀死进程，执行下一进程，这种“条件”通常是通过程序的输出来反馈的。我们不希望一直盯着屏幕来观察条件是否达到，用bash脚本来执行这种任务是一个明智的选择。 问题描述我要做的事情可以用下面的流程图描述。该任务的目标是检查不同的配置参数对训练运行速度的影响。 使用bash脚本监控程序运行bash脚本如下。思路是训练程序的输出重定向到文件mx_alexnet.log，然后每隔2秒用tail查看mx_alexnet.log的最后一行，检测loss的最新值, 如果达到target，就结束程序，然后重新开始。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#!/bin/bashfunction run()&#123; interval=2 target=1.5 logfile=mx_alexnet.log # set knobs export MXNET_CPU_WORKER_NTHREADS=$1 export MXNET_CPU_PRIORITY_NTHREADS=$2 export MXNET_CPU_NNPACK_NTHREADS=$3 export MXNET_EXEC_ENABLE_INPLACE=$4 # start training python code/train_imagenet.py --network alexnet \ --num-classes 8 \ --data-train /root/zl_workspace/dataset/imagenet8/mxnet-format/train_rec.rec \ --data-val /root/zl_workspace/dataset/imagenet8/mxnet-format/val_rec.rec \ --num-examples 10400 \ --num-epochs 20 \ --loss 'ce' \ --disp-batches 1 \ --batch-size 256 \ --lr 0.01 \ --lr-step-epochs 5,10 \ &gt;$logfile 2&gt;&amp;1 &amp; # stat the time begin_time=$(date +%s) sleep 10 # monitor loss for((;;)) do tail -n1 $logfile loss=$(tail -n1 $logfile | sed -n 's/.*\scross-entropy=\([0-9]\+.[0-9]\+\)*/\1/p') if [ -n "$loss" ] then if [ $(echo "$&#123;loss&#125; &lt; $&#123;target&#125;" | bc) -eq 1 ] then break else sleep $interval fi else sleep $interval fi done # record the time of runnig end_time=$(date +%s) run_time=$((end_time - begin_time)) echo "$1, $2, $3, $4, $run_time" &gt;&gt; "$5" echo "training finshed! Cost $&#123;run_time&#125; s." # kill the process ps aux | grep "python code/train_imagenet.py" | grep -v "grep" | awk &#123;'print $2'&#125; | xargs kill echo "killed process successfully!" rm -f $logfile echo "finished removal successfully!"&#125;# make sure the training is not going currentlyps aux | grep "python code/train_imagenet.py" | grep -v "grep" | awk &#123;'print $2'&#125; | xargs kill# create a file to record running timerfile=results.csvtouch $rfileecho "mcwn, mcpn, mcnn, meei, run_time" &gt; $rfilefor mcwn in 1 2 4 8; do for mcpn in 4 1 2 8; do for mcnn in 4 1 2 8; do for meei in true false; do if [ $(($mcwn + $mcpn + $mcnn)) -le 16 ] then run $mcwn $mcpn $mcnn $meei $rfile echo "waiting for restart..." sleep 10 fi done done donedone 几个细节bash中比较浮点数的大小bash本身是只支持比较整数的大小，要比较浮点数大小需要借助程序bc，所以上面中的代码中检测loss值用的是12if [ $(echo "$&#123;loss&#125; &lt; $&#123;target&#125;" | bc) -eq 1 ] ... 而不是1if [ $&#123;loss&#125; &lt; $&#123;target&#125; ] 详情请 在terminal下man bc。 bash中的复合逻辑表达式注意脚本中的这一段1234567891011if [ -n "$loss" ] then if [ $(echo "$&#123;loss&#125; &lt; $&#123;target&#125;" | bc) -eq 1 ] then break else sleep $interval fielse sleep $intervalfi 为什么不写成下面这样？123456if [ -n "$loss" -a $(echo "$&#123;loss&#125; &lt; $&#123;target&#125;" | bc) -eq 1 ]then breakelse sleep $intervalfi 因为bash脚本中的复合逻辑表达式不像C语言中那样会被优化，当正则表达式没有匹配到值而使loss为空时，尽管-n &quot;$loss&quot;为真，-a后面的 $(echo &quot;${loss} &lt; ${target}&quot; | bc) -eq 1仍然会执行，然后就会报错。 bash script教程及几个常用的命令bash教程：中文-英文 本文中涉及的几个常用的命令 sed: here grep: here awk: here xargs: 教程[1] - 教程[2]]]></content>
      <categories>
        <category>人生经验</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Solve "libstdc++.so.6:&ensp;version CXXABI_1.3.8 not found"]]></title>
    <url>%2F2018%2F08%2F24%2Fusr-lib64-libstdc-so-6-version-CXXABI-1-3-8-not-found%2F</url>
    <content type="text"><![CDATA[libstdc++.so.6:version CXXABI_1.3.8 not found错误出现的原因是libstdc++.so.6的版本太旧。这个问题在CentOS中尤其容易出现, 因为目前yum的源中维护的gcc版本比较旧(4.8.5)。这个问题可以通过安装较新版本的gcc解决。 安装gcc如果你的系统支持用包管理工具(比如apt)安装新版gcc，那么问题就已经解决了；如果不支持（比如在CentOS上），那么就源码安装gcc吧。 从https://ftp.gnu.org/gnu/gcc/gcc-7.3.0/gcc-7.3.0.tar.gz下载安装包 依次执行下面的命令 1234567tar -xvf gcc-7.3.0.tar.gzcd gcc-7.3.0yum install libmpc-devel mpfr-devel gmp-devel./configure --with-system-zlib --disable-multilib --enable-languages=c,c++make -j 8make installgcc --version 完事记得检查新的libstdc++.so.6在哪里 1find / -name libstdc++.so.6 将该目录加入环境变量LD_LIBRARY_PATH(一般是/usr/local/lib或/usr/local/lib64里面那个，如果不确定的话用strings /path/to/libstdc++.so | grep CXXABI_1.3.8检查一下) 注意事项：devtoolset-x解决不了你的问题如果你是用devtoolset-x安装的gcc，那么libstdc++.so.6:version CXXABI_1.3.8 not found还是解决不了，因为 the devtoolset-x packages actually just wrap the standard system libstdc++.so 参考这里[1]。 参考[1]https://stackoverflow.com/questions/46172600/usr-lib64-libstdc-so-6-version-cxxabi-1-3-8-not-found]]></content>
      <categories>
        <category>人生经验</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>gcc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Miscellaneous]]></title>
    <url>%2F2018%2F08%2F21%2FMiscellaneous%2F</url>
    <content type="text"><![CDATA[This post will be used to keep track of daily bugs, workaroud, solutions, collections,links and so on. linuxinode两个很好的参考链接： 阮一峰的日志 鸟哥的linux私房菜 概括： 磁盘分为inode区和data block区，磁盘一经格式化就会少一部分空间，这部分空间被inode区占用。尽管分配时是按磁盘块比例分配的，在后续使用中实际上是一个inode对应一个文件，一个文件可能对应多个inode, 因既有可能出现inode用完而data block还有空余空间的情况(每个文件都太小，比如，只占一个block)，也有可能出现inode还剩很多，但data block已经装满的情况(每个文件都很大)。 文件目录也是文件，它有inode，也有data blocks，它的data blocks里以[\&lt;inode> \&lt;filename>}]的格式记录该目录下文件名-&gt;inode号的映射 inode里面除了data block的索引区块（分为直接索引，一次间址， 两次间址， 三次间址）外，还有一些文件的元信息，如权限，修改时间，大小等。用stat &lt;filename&gt;命令可以查看。 对于目录，天生具有两个硬链接，一个在其父目录下，一个是本身下面的.，所以一个目录的links = 2 + “普通”子目录个数（“普通”的意思是不包含.和..） 考虑到查找文件的性能，linux源码中规定一个目录下最多只能包含3200个子文件（考虑.和..还要减去2），所以目录文件的大小并不能达到单个文件的理论最大值（来源） 一图胜千言。下图中的黄色表格是目录的data block ubuntu 18.04 安装opencv参考这个链接cntk依赖3.1版，这个目前会安装3.2版，一个workaround是创建软链接欺骗cntk。 xx &gt; /dev/null 2&gt;&amp;1 的意义 意义：将xx的STDOUT重定位到/dev/null(黑洞), STDERR重定位到STDOUT，总的来说就是把程序的任何输出都丢到黑洞。 1前面为什么要加&amp;：如果不加，STDERR就会重定位到一个文件，文件名为’1’。加&amp;予以区分。(来源) Shellshell tutorial中文 英文 Syntax error: Bad for loop variable检查你是不是用sh执行脚本的？是的话换bash看看。sh不支持for循环。 bash脚本比较浮点数大小bash本身只支持比较整数，要比较浮点数大小用下面的方式(来源):1234if [ $(echo "23.3 &gt; 7.3" | bc) -ne 0 ] then echo "wassup"fi bash脚本中的布尔表达式需要注意的是，bash脚本中的布尔表达式不会像C语言中一样被优化。这可能是引起下面错误的原因。 12[: too many arguments[: unary operator expected git官方文档是坠吼的：English-中文 .gitignore快速教程一个例子,来自这里1234567# 此为注释 – 将被 Git 忽略 *.a # 忽略所有 .a 结尾的文件!lib.a # 但 lib.a 除外/TODO # 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODObuild/ # 忽略 build/ 目录下的所有文件doc/*.txt # 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt 解决.gitignore不生效把暂存区缓存清除123git rm -r --cached .git add .git commit -m &apos;update .gitignore&apos; apt/apt-getadd-apt-repository后apt update报错1E: The repository &apos;http://ppa.launchpad.net/gummi/gummi/ubuntu bionic Release&apos; does not have a Release file 解决方法在这里123sudo add-apt-repository --remove ppa:gummi/gummisudo apt updatesudo apt install gummi Never add a PPA if you don’t have to. 深度学习用Alexnet在cifar10上训练报错Alexnet的第一层的卷积核以及步长是多大？过完两层之后特征图还有多大？如果你一定要在cifar10上训练Alexnet, 要么在预处理时把图放大一下尺寸，要么修改Alexnet各层的卷积核和池化窗口大小。 Tensorflowtensoflow low level apiclick here 有关tensorflow的一些基础概念以及低级的api都在这里。只使用高级api可能永远不知道模型里面发生了什么，还有就是有时候真的需要更低级的api，复杂意味着灵活，简单意味着死板。 MXNet多机训练参考以下两个官方文档： Large Scale Image Classification Distributed Training in MXNet Trouble shooting多机训练时可能报错： 1mxnet/src/io/iter_image_recordio_2.cc:318: Check failed: !overflow number of input images must be bigger than the batch size 出现这个问题的原因是验证集中#example &lt; #worker * batch_size。解决方案： 用更小的batch_size 减少worker数量 在训练时禁用验证集]]></content>
      <categories>
        <category>见得多了</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>deep learning</tag>
        <tag>git</tag>
        <tag>apt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[obtain the loss value efficiently: don't do superfluous forward passes in training loop]]></title>
    <url>%2F2018%2F08%2F21%2Fobtain-the-loss-value-efficiently-don-t-do-superfluous-forward-passes-in-training-loop%2F</url>
    <content type="text"><![CDATA[在利用Tensorflow或CNTK训练DNN的时候，我们可能需要在一次迭代后获得当前的loss或者其他metric。一种常见的方式是：通过一次forward pass计算loss(比如tensorflow的loss.eval())。但是这样带来的额外消耗是没有必要的，因为在训练过程中已经进行过forward pass。 在迭代完成后打印当前的损失值我有一份用CNTK实现的DNN，它的training loop长这样123456789101112131415...ce = C.cross_entropy_with_softmax(z, label_var)pe = C.classification_error(z, label_var)......# training toopfor epoch in range(1, max_epochs+1): sample_count = 0 while sample_count &lt; epoch_size: data = reader_train.next_minibatch(min(minibatch_size, epoch_size - sample_count), input_map=input_map) trainer.train_minibatch(data) sample_count += data[label_var].num_samples trainer.summarize_training_progress()... 但是我希望每完成一个mini batch的训练我都能及时获得当前的loss，因为我希望： 能够在每次迭代后打印当前的loss值 当loss达到某个给定的target_loss的时候就停止训练 一种很自然的想法就是像下面这样：12345678910111213141516...ce = C.cross_entropy_with_softmax(z, label_var)pe = C.classification_error(z, label_var)......# training toopfor epoch in range(1, max_epochs+1): sample_count = 0 while sample_count &lt; epoch_size: data = reader_train.next_minibatch(min(minibatch_size, epoch_size - sample_count), input_map=input_map) trainer.train_minibatch(data)--&gt; curr_loss = np.asscalar(np.mean(ce.eval(data)))--&gt; print("current loss: %f" % (curr_loss)) sample_count += data[label_var].num_samples... 然而我发现这样会拖慢迭代的速度，在加上这两行之前，训练一个256个examples的mini batch大约是13s， 加上后则需要17~18s，显然问题出在curr_loss = np.asscalar(np.mean(ce.eval(data)))这里，进行一次forward pass还是挺耗时的。 正确的方式我们知道在trainer.train_minibatch(data)中是进行过forward pass的，那么看看trainer.train_minibatch()有没有提供这样的接口，从API文档[1]中我们可以看到： 注意红色方框标记的内容。简单地说，反正可以通过传入outputs参数输出制定的令trainer.train_minibatch()以字典的方式返回请求获取的值。最终代码如下：12345678910111213141516171819202122232425262728293031...ce = C.cross_entropy_with_softmax(z, label_var)pe = C.classification_error(z, label_var)......# train loopfinished = Falsefor epoch in range(1, max_epochs+1): if finished: logging.info("Training finished!") break sample_count = 0 batch_cnt = 1 while sample_count &lt; epoch_size: batch_begin_time = time.time() data = reader_train.next_minibatch(min(minibatch_size, epoch_size - sample_count), input_map=input_map)--&gt; _, dict_out = trainer.train_minibatch(data, outputs=[ce, pe])--&gt; curr_loss = np.asscalar(np.mean(dict_out[ce]))--&gt; curr_err_rate = np.asscalar(np.mean(dict_out[pe])) logging.info("epoch[%d of %d] - batch[%d] - training loss=%f - training err_rate = %f %% - %f exampls/s"% (epoch, max_epochs, batch_cnt, curr_loss, curr_err_rate*100, data[label_var].num_samples/(time.time()-batch_begin_time) ) ) sample_count += data[label_var].num_samples batch_cnt += 1 if curr_loss &lt; target_loss: finished = True break... 这样更改之后，我实现了打印loss和用loss控制训练结束，并且训练速度恢复到了约13 s/batch。 注意 : outputs参数需要传入一个iterable的对象，因此即使你只希望取loss一个值，也应该使用trainer.train_minibatch(data, outputs=[loss])而不是trainer.train_minibatch(data, outputs=loss) Tensorflow中该如何做同样的问题，在tensorflow中你应该使用[2] 123456for i in range(100): batch_xs, batch_ys = mnist.train.next_batch(100) cross_entropy = -tf.reduce_sum(y_ * tf.log(y)) _, loss_val = sess.run([train_step, cross_entropy], feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;) print 'loss = ' + loss_val 而不是1234567for i in range(100): batch_xs, batch_ys = mnist.train.next_batch(100) cross_entropy = -tf.reduce_sum(y_ * tf.log(y)) sess.run(train_step, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;) loss_val = sess.run(cross_entropy) print 'loss = ' + loss_val 下面的例子可以看出两种方式运行时间的差别 参考[1]https://www.cntk.ai/pythondocs/cntk.train.trainer.html [2] https://stackoverflow.com/questions/33833818/printing-the-loss-during-tensorflow-training]]></content>
      <categories>
        <category>人生经验</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Train Alexnet on imagenet-8 using CNTK]]></title>
    <url>%2F2018%2F08%2F19%2FTrain-alexnet-on-imagenet-8-using-CNTK%2F</url>
    <content type="text"><![CDATA[为了做某个与项目有关的评测，我需要在imagenet-8（imagenet的一个子集，只包含前八类的训练数据和测试数据）上用CNTK训练Alexnet。官方提供了Alexnet基于CNTK的python实现，但是却无法直接执行，因为脚本需要数据集中包含一个叫map file的东西。 问题在开始训练前，我已经准备好了imagenet8训练集放在~/dataset/目录下,目录结构如下1234567891011121314151617181920212223242526272829leizhu@pc-office:~/dataset$ tree -d.└── imagenet8 ├── mxnet-format │ ├── train │ ├── train_meta │ ├── val │ └── val_meta └── raw ├── train │ ├── n01440764 │ ├── n01443537 │ ├── n01484850 │ ├── n01491361 │ ├── n01494475 │ ├── n01496331 │ ├── n01498041 │ └── n01514668 └── validation ├── n01440764 ├── n01443537 ├── n01484850 ├── n01491361 ├── n01494475 ├── n01496331 ├── n01498041 └── n0151466825 directories 然后我从CNTK的github仓库中下载了Alexnet的Python实现[1]，并执行该脚本：1python AlexNet_ImageNet_Distributed.py --datadir ~/dataset/imagenet8/raw/ 结果报错1RuntimeError: File &apos;/home/leizhu/dataset/imagenet8/raw/train_map.txt&apos; does not exist. 那么train_map.txt是什么呢？几经周折找到一个实例文件[2]，它长这个样子：12345678val1024.zip@/ILSVRC2012_val_00000001.JPEG 65val1024.zip@/ILSVRC2012_val_00000002.JPEG 970val1024.zip@/ILSVRC2012_val_00000003.JPEG 230val1024.zip@/ILSVRC2012_val_00000004.JPEG 809val1024.zip@/ILSVRC2012_val_00000005.JPEG 516val1024.zip@/ILSVRC2012_val_00000006.JPEG 57val1024.zip@/ILSVRC2012_val_00000007.JPEG 334val1024.zip@/ILSVRC2012_val_00000008.JPEG 415 看起来每一行都是&lt;图象路径&gt; + &lt;标签&gt;。根据链接[3]中的代码，应该就是了。 解决方案编写下面的python脚本1234567891011121314151617181920212223242526272829303132import osimport argparsedef generate_map_file(abs_data_dir): train_dir = os.path.join(abs_data_dir, "train") val_dir = os.path.join(abs_data_dir, "validation") class_dirs = os.listdir(train_dir) with open(os.path.join(abs_data_dir, "train_map.txt"), "w") as f: for i in range(len(class_dirs)): pic_dirname = os.path.join(train_dir, class_dirs[i]) for pic in os.scandir(pic_dirname): if pic.is_file() and pic.name.endswith('.JPEG'): f.write("%s\t%d\n"%(os.path.join(pic_dirname,pic),i)) with open(os.path.join(abs_data_dir, "val_map.txt"), "w") as f: for i in range(len(class_dirs)): pic_dirname = os.path.join(val_dir, class_dirs[i]) for pic in os.scandir(pic_dirname): if pic.is_file() and pic.name.endswith('.JPEG'): f.write("%s\t%d\n"%(os.path.join(pic_dirname,pic),i)) print("generate mapfile successfully!\n")if __name__ == "__main__": parser = argparse.ArgumentParser(description = "generate mapfile") parser.add_argument("--data_dir", type=str, default="/home/leizhu/dataset/imagenet8/raw/", help="absolute path of data directory") args = parser.parse_args() generate_map_file(args.data_dir) 然后执行1python map_file.py --data_dir ~/dataset/imagenet8/raw 再进行训练就没有问题了。 如果你要根据元文件(应该是个xml?我没有原始数据集，太大了下不动)为原始的imagenet ILSVRC数据集生成map file，请参考这里[4]。 referrence[1]https://github.com/Microsoft/CNTK/blob/master/Examples/Image/Classification/AlexNet/Python/AlexNet_ImageNet_Distributed.py [2]https://github.com/Microsoft/CNTK/blob/master/Tests/EndToEndTests/Image/AlexNet/train_map.txt [3]https://cntk.ai/pythondocs/CNTK_201A_CIFAR-10_DataLoader.html [4]https://github.com/Microsoft/CNTK/issues/2091]]></content>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决error:&ensp; Your local changes to the following files would be overwritten by merge]]></title>
    <url>%2F2018%2F08%2F18%2Fsolve-an-error-caused-by-git-pull%2F</url>
    <content type="text"><![CDATA[本文介绍决执行git pull时，错误error: Your local changes to the following files would be overwritten by merge的产生原因和解决方法。 问题git pull博客源代码仓库的时候发现冲突 123456[Leif@pc90005 blog]$ git pullUpdating f89b7be..01cc068error: Your local changes to the following files would be overwritten by merge: _config.ymlPlease commit your changes or stash them before you merge.Aborting 执行git status检查目录状态显示如下 1234567891011121314151617181920[Leif@pc90005 blog]$ git statusOn branch srcYour branch is behind &apos;origin/src&apos; by 1 commit, and can be fast-forwarded. (use &quot;git pull&quot; to update your local branch)Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: _config.ymlUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) source/_posts/MXNet-alexnet-cifar10.md source/_posts/MXNet-stop-training-by-loss.md source/_posts/git-submodule.md source/_posts/ssh-collection.mdno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 原因从上面的结果来看，是因为我修改了_config.yml，导致该文件和服务器上最新的版本不同导致的合并冲突。此时如果git将服务器上的_config.yml（为了区分，记为_config.yml[remote]）拉下来直接覆盖本地文件（记为_config.yml[local]），那么_config.yml[local]中所做的更改就再也找不回来了，这是因为_config.yml[local]还没有commit。git不会擅做这种主张，导致你没有后悔药吃。 解决方案checkout:丢弃本地所做的更改1git checkout HEAD _config.yml 此时执行git pull， git发现当前工作区是干净的，就放心地将_config.yml[remote]下拉回来了。注意，这样的话，你等于主动丢弃_config.yml[local]中所做的更改，这些更改无法恢复。 commit: 将修改提交到仓库1git commit -a -m &quot;modified _config.yml&quot; 同样地，这时工作区是干净的，所以git pull也没有问题。因为已经提交到仓库，你总是有办法找回_config.yml[local]。 stash: 将当前的工作目录另存到储藏栈上如果你不想丢失_config.yml[local]又不想因为这么一点小小的改动就创建一次commit（比如，你希望至少完成一篇博客才做一次提交），那么可以使用git stash。按序执行以下三条命令可以让你将_config.yml[remote]下拉回来，然后和_config.yml[local]合并 123git stashgit pullgit stash pop 关于stash的功能和用法可以参考[1]。简单来说，git stash会 先将你当前的工作目录暂存到一个“储藏栈”的栈顶（这个储藏栈和“暂存区”或者“仓库”不是一个地方） 然后恢复到你上次提交完的状态(相当于再执行git reset --hard) 而git stash pop则会 “储藏栈”栈顶的一次暂存和当前工作目录中文件合并 然后删除储藏栈顶的暂存。 参考[1]https://git-scm.com/book/zh/v2/Git-工具-储藏与清理]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Install cntk on Ubuntu 18.04]]></title>
    <url>%2F2018%2F08%2F17%2Finstall-cntk-on-Ubuntu-18-04%2F</url>
    <content type="text"><![CDATA[按照官网教程[1]，用pip安装cntk仅需简单两步，但是在实际操作中，安装完毕后可能会报错。本文对安装过程做简单总结。 CNTK-Python 安装过程顺次执行下列命令1sudo apt install openmpi-bin (cntk用的是mpi而不是parameter server架构？？？)1pip install cntk (如果要安装支持gpu的版本，请将cntk替换为cntk-gpu) 然后用下面的命令检查cntk是否安装成功1python -c &quot;import cntk; print(cntk.__version__)&quot; Troubleshooting找不到libmpi_cxx.so.1或libmpi.so.12运行 python -c &quot;import cntk; print(cntk.__version__)&quot;时可能显示以下错误123456789101112131415161718192021222324leizhu@pc-office:~$ python -c &quot;import cntk; print(cntk.__version__)&quot;Traceback (most recent call last): File &quot;/home/leizhu/anaconda3/lib/python3.6/site-packages/cntk/cntk_py.py&quot;, line 18, in swig_import_helper return importlib.import_module(mname) File &quot;/home/leizhu/anaconda3/lib/python3.6/importlib/__init__.py&quot;, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 994, in _gcd_import File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 971, in _find_and_load File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 953, in _find_and_load_unlockedModuleNotFoundError: No module named &apos;cntk._cntk_py&apos;During handling of the above exception, another exception occurred:Traceback (most recent call last): File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt; File &quot;/home/leizhu/anaconda3/lib/python3.6/site-packages/cntk/__init__.py&quot;, line 17, in &lt;module&gt; from . import cntk_py File &quot;/home/leizhu/anaconda3/lib/python3.6/site-packages/cntk/cntk_py.py&quot;, line 21, in &lt;module&gt; _cntk_py = swig_import_helper() File &quot;/home/leizhu/anaconda3/lib/python3.6/site-packages/cntk/cntk_py.py&quot;, line 20, in swig_import_helper return importlib.import_module(&apos;_cntk_py&apos;) File &quot;/home/leizhu/anaconda3/lib/python3.6/importlib/__init__.py&quot;, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)ImportError: libmpi_cxx.so.1: cannot open shared object file: No such file or directory 执行下面的命令解决[2]1sudo ln -s /usr/lib/x86_64-linux-gnu/libmpi_cxx.so.20 /usr/lib/x86_64-linux-gnu/libmpi_cxx.so.1 对于找不到libmpi.so.12的情况同上处理1sudo ln -s /usr/lib/x86_64-linux-gnu/libmpi.so.20.10.1 /usr/lib/x86_64-linux-gnu/libmpi.so.12 此时再执行python -c &quot;import cntk; print(cntk.__version__)&quot;应正常输出版本号。 找不到libpng12.so.0和libjasper.so.1后来在试跑Alexnet的时候又遇到了RuntimeError，先是找不到libpng12.so.0 1RuntimeError: Plugin not found: &apos;Cntk.Deserializers.Image-2.5.1.so&apos; (error: libpng12.so.0: cannot open shared object file: No such file or directory) 解决方式如下[3]123wget -q -O /tmp/libpng12.deb http://mirrors.kernel.org/ubuntu/pool/main/libp/libpng/libpng12-0_1.2.54-1ubuntu1_amd64.debsudo dpkg -i /tmp/libpng12.debrm /tmp/libpng12.deb 然后又找不到libjasper.so.11RuntimeError: Plugin not found: &apos;Cntk.Deserializers.Image-2.5.1.so&apos; (error: libjasper.so.1: cannot open shared object file: No such file or directory) 解决方法[4]：123sudo add-apt-repository &quot;deb http://security.ubuntu.com/ubuntu xenial-security main&quot;sudo apt updatesudo apt install libjasper1 libjasper-dev &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;更新&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; BrainScript API 安装及报错处理要使用Brainscript，必须源码安装CNKT。这个太小众了，要不是有特殊需要我才懒得装。下面的介绍从简。 安装方法参考这个页面[5]建议用Manual install方式。 解决libiomp5.so和libmklml_intel.so缺失安装Intel Math Kernel Library (MKL), 参考这里[6](网上一堆说用source /opt/intel/bin/compilervars.sh intel64的，但是只有安装了Intel的编译器才会有/opt/intel/bin/compilervars.sh这个文件，而且安装了也只能解决libiomp5.so的问题。其实直接安装libmklml_intel.so就好。) 参考[1]https://docs.microsoft.com/en-us/cognitive-toolkit/setup-linux-python?tabs=cntkpy251 [2]https://tweaks-tips.blogspot.com/2017/12/microsoft-cntk-libmpi-importerror.html [3]https://github.com/tcoopman/image-webpack-loader/issues/95 [4]https://stackoverflow.com/questions/43484357/opencv-in-ubuntu-17-04/43507858 [5]https://docs.microsoft.com/en-us/cognitive-toolkit/Install-CNTK-BrainScript#manual-install-1 [6]https://software.intel.com/en-us/articles/intel-mkl-dnn-part-1-library-overview-and-installation]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Make software work properly behind proxy]]></title>
    <url>%2F2018%2F08%2F10%2Fmake-software-work-properly-behind-proxy%2F</url>
    <content type="text"><![CDATA[系里的以太网访问互联网必须经过代理。然而我发现如果仅仅设置系统代理，一些命令(apt update, npm等)仍然无法建立连接，而需要单独设置。记录踩坑过程如下。我使用的系统是Ubuntu 18.04 LTS. 系统代理有一些软件（比如Chrome和Firefox, 命令行中的pip）会默认使用系统代理，也就是说，只要你正确设置了系统代理，这部分软件就能正常联网了。 通过图形界面设置前往Settings -&gt; Network -&gt; Network Proxy -&gt; Manual， 然后如下图所示 注意：填写的地址不要包含“http://”或”https://“字段,直接填写域名或ip. (一定要皮一下加上？那好，在命令行下执行”echo $HTTP_PROXY”，看到了什么？在我测试的Ubuntu 18.04下此时仍然可以正常上网，但是一些命令行软件却无法建立互联网连接了) 通过命令行设置当然，你也可以在命令行下修改，也就是HTTPS_PROXY和HTTP_PROXY加入环境变量。但是由于在图形界面添加的代理没有问题，我没有尝试。有点担心这样能否对对图形界面的程序（比如浏览器）生效。 注意：不管是HTTPS_PROXY还是HTTP_PROXY,都应该设置为”http://…”，如果你将HTTPS_PROXY设为”https://…”，有些软件就不能正常使用了，请参考[3]。 关于GUI和命令行设置代理的区别一个非常有趣的现象是，当我通过GUI设置代理之后，尽管在终端中能通过12echo $HTTP_PROXYecho $HTTPS_PROXY 查看代理环境变量，但是却无法在/etc/environment或者/etc/bash.bashrc或者/etc/.bashrc中发现关于这两个环境变量的记录。我原以为通过GUI设置就会将代理变量写入这些文件。[1]中提到： 如果在GUI设置时apply systme wide (我的Ubuntu 18.04没有该选项)，那么环境变量就会写入/etc/environment 和 /etc/apt/apt.conf， 否则代理变量只存放在gsettings database(就是GUI的数据库？)中。 通过在.bashrc添加代理环境变量通过不会对图形界面程序生效。 不默认使用系统代理的软件apt设置完系统代理后，sudo apt install命令可以正常联网安装软件了，奇怪的是sudo apt update 和 sudo apt add-apt-repository均无法建立互联网连接。一个快速的解决方式如下12sudo -E apt install sofware-namesudo -E apt add-apt-repository ppa:xx/yy 关于这么做的原理，可以参考[2]，简单来说，sudo执行命令时默认不会保留当前用户的环境变量，而-E参数使得环境变量得以保留。（那么为啥不加-E参数时, sudo apt install没毛病呢? emmmmm, 我也不知道） 当然也可以在apt内设置代理:123456sudo vim /etc/apt/apt.conf然后在apt.conf中添加下面两行并保存Acquire::http::proxy &quot;http://lgn:pwd@proxy_sever:proxy_port&quot;;Acquire::https::proxy &quot;http://lgn:pwd@proxy_sever:proxy_port&quot;;如果代理服务器不需要账户和密码则不需要lgn:pwd@字段。 git系统代理设置完成后使用git克隆远程github仓库发现没有响应，使用的命令如下：1git clone git@github.com:LeifZhu/LeifZhu.github.io.git 因为这时使用的是ssh协议，穿不透代理。你可以选择换成clone with https，即执行1git clone https://github.com/LeifZhu/LeifZhu.github.io.git 或者参考[4]或者[5]通过https支持ssh协议。以我的使用为例先安装corkscrew1sudo apt install corkscrew 然后修改~/.ssh/config,添加123456Host github.com User git Hostname ssh.github.com Port 443 ProxyCommand /usr/bin/corkscrew proxy.cse.cuhk.edu.hk 8000 %h %p IdentityFile ~/.ssh/id_rsa 总结 在图形界面设置系统代理时不要加上协议头”http://“ 即使设置了系统代理，一些软件也可能需要在软件内再设置代理。如果你发现浏览器能上网而命令行软件不能，那么你应该考虑配置软件内代理，或者对于sudo命令加上-E参数。 无论是HTTP_PROXY,还是HTTPS_PROXY,都应该设置为”http://…” 参考[1]https://askubuntu.com/questions/830796/proxy-config-gui-vs-setting-http-proxy-in-etc-environment [2]https://stackoverflow.com/questions/8633461/how-to-keep-environment-variables-when-using-sudo [3]https://serverfault.com/questions/817680/https-through-an-http-only-proxy [4]https://unix.stackexchange.com/questions/190490/how-to-use-ssh-over-http-or-https [5]https://blog.csdn.net/twilightdream/article/details/78260394]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
</search>
