<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[使用bash脚本监控程序输出并自动执行任务]]></title>
    <url>%2F2018%2F09%2F02%2F%E4%BD%BF%E7%94%A8bash%E8%84%9A%E6%9C%AC%E7%9B%91%E6%8E%A7%E7%A8%8B%E5%BA%8F%E8%BE%93%E5%87%BA%E5%B9%B6%E8%87%AA%E5%8A%A8%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[Solve "libstdc++.so.6:&ensp;version CXXABI_1.3.8 not found"]]></title>
    <url>%2F2018%2F08%2F24%2Fusr-lib64-libstdc-so-6-version-CXXABI-1-3-8-not-found%2F</url>
    <content type="text"><![CDATA[libstdc++.so.6:version CXXABI_1.3.8 not found错误出现的原因是libstdc++.so.6的版本太旧。这个问题在CentOS中尤其容易出现, 因为目前yum的源中维护的gcc版本比较旧(4.8.5)。这个问题可以通过安装较新版本的gcc解决。 安装gcc如果你的系统支持用包管理工具(比如apt)安装新版gcc，那么问题就已经解决了；如果不支持（比如在CentOS上），那么就源码安装gcc吧。 从https://ftp.gnu.org/gnu/gcc/gcc-7.3.0/gcc-7.3.0.tar.gz下载安装包 依次执行下面的命令 1234567tar -xvf gcc-7.3.0.tar.gzcd gcc-7.3.0yum install libmpc-devel mpfr-devel gmp-devel./configure --with-system-zlib --disable-multilib --enable-languages=c,c++make -j 8make installgcc --version 完事记得检查新的libstdc++.so.6在哪里 1find / -name libstdc++.so.6 将该目录加入环境变量LD_LIBRARY_PATH(一般是/usr/local/lib或/usr/local/lib64里面那个，如果不确定的话用strings /path/to/libstdc++.so | grep CXXABI_1.3.8检查一下) 注意事项：devtoolset-x解决不了你的问题如果你是用devtoolset-x安装的gcc，那么libstdc++.so.6:version CXXABI_1.3.8 not found还是解决不了，因为 the devtoolset-x packages actually just wrap the standard system libstdc++.so 参考这里[1]。 参考[1]https://stackoverflow.com/questions/46172600/usr-lib64-libstdc-so-6-version-cxxabi-1-3-8-not-found]]></content>
      <categories>
        <category>人生经验</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>gcc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Miscellaneous]]></title>
    <url>%2F2018%2F08%2F21%2FMiscellaneous%2F</url>
    <content type="text"><![CDATA[This post will be used to keep track of daily bugs, workaroud, solutions, collections,links and so on. linuxinode两个很好的参考链接： 阮一峰的日志 鸟哥的linux私房菜 概括： 磁盘分为inode区和data block区，磁盘一经格式化就会少一部分空间，这部分空间被inode区占用。尽管分配时是按磁盘块比例分配的，在后续使用中实际上是一个inode对应一个文件，一个文件可能对应多个inode, 因既有可能出现inode用完而data block还有空余空间的情况(每个文件都太小，比如，只占一个block)，也有可能出现inode还剩很多，但data block已经装满的情况(每个文件都很大)。 文件目录也是文件，它有inode，也有data blocks，它的data blocks里以[\&lt;inode> \&lt;filename>}]的格式记录该目录下文件名-&gt;inode号的映射 inode里面除了data block的索引区块（分为直接索引，一次间址， 两次间址， 三次间址）外，还有一些文件的元信息，如权限，修改时间，大小等。用stat &lt;filename&gt;命令可以查看。 对于目录，天生具有两个硬链接，一个在其父目录下，一个是本身下面的.，所以一个目录的links = 2 + “普通”子目录个数（“普通”的意思是不包含.和..） 考虑到查找文件的性能，linux源码中规定一个目录下最多只能包含3200个子文件（考虑.和..还要减去2），所以目录文件的大小并不能达到单个文件的理论最大值（来源） 一图胜千言。下图中的黄色表格是目录的data block ubuntu 18.04 安装opencv参考这个链接cntk依赖3.1版，这个目前会安装3.2版，一个workaround是创建软链接欺骗cntk。 xx &gt; /dev/null 2&gt;&amp;1 的意义 意义：将xx的STDOUT重定位到/dev/null(黑洞), STDERR重定位到STDOUT，总的来说就是把程序的任何输出都丢到黑洞。 1前面为什么要加&amp;：如果不加，STDERR就会重定位到一个文件，文件名为’1’。加&amp;予以区分。(来源) Shellshell tutorial中文 英文 Syntax error: Bad for loop variable检查你是不是用sh执行脚本的？是的话换bash看看。sh不支持for循环。 bash脚本比较浮点数大小bash本身只支持比较整数，要比较浮点数大小用下面的方式(来源):1234if [ $(echo "23.3 &gt; 7.3" | bc) -ne 0 ] then echo "wassup"fi bash脚本中的布尔表达式需要注意的是，bash脚本中的布尔表达式不会像C语言中一样被优化。这可能是引起下面错误的原因。 12[: too many arguments[: unary operator expected git官方文档是坠吼的：English-中文 .gitignore快速教程一个例子,来自这里1234567# 此为注释 – 将被 Git 忽略 *.a # 忽略所有 .a 结尾的文件!lib.a # 但 lib.a 除外/TODO # 仅仅忽略项目根目录下的 TODO 文件，不包括 subdir/TODObuild/ # 忽略 build/ 目录下的所有文件doc/*.txt # 会忽略 doc/notes.txt 但不包括 doc/server/arch.txt 解决.gitignore不生效把暂存区缓存清除123git rm -r --cached .git add .git commit -m &apos;update .gitignore&apos; apt/apt-getadd-apt-repository后apt update报错1E: The repository &apos;http://ppa.launchpad.net/gummi/gummi/ubuntu bionic Release&apos; does not have a Release file 解决方法在这里123sudo add-apt-repository --remove ppa:gummi/gummisudo apt updatesudo apt install gummi Never add a PPA if you don’t have to. 深度学习用Alexnet在cifar10上训练报错Alexnet的第一层的卷积核以及步长是多大？过完两层之后特征图还有多大？如果你一定要在cifar10上训练Alexnet, 要么在预处理时把图放大一下尺寸，要么修改Alexnet各层的卷积核和池化窗口大小。 Tensorflowtensoflow low level apiclick here 有关tensorflow的一些基础概念以及低级的api都在这里。只使用高级api可能永远不知道模型里面发生了什么，还有就是有时候真的需要更低级的api，复杂意味着灵活，简单意味着死板。 MXNet多机训练参考以下两个官方文档： Large Scale Image Classification Distributed Training in MXNet Trouble shooting多机训练时可能报错： 1mxnet/src/io/iter_image_recordio_2.cc:318: Check failed: !overflow number of input images must be bigger than the batch size 出现这个问题的原因是验证集中#example &lt; #worker * batch_size。解决方案： 用更小的batch_size 减少worker数量 在训练时禁用验证集]]></content>
      <categories>
        <category>见得多了</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>deep learning</tag>
        <tag>git</tag>
        <tag>apt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[obtain the loss value efficiently: don't do superfluous forward passes in training loop]]></title>
    <url>%2F2018%2F08%2F21%2Fobtain-the-loss-value-efficiently-don-t-do-superfluous-forward-passes-in-training-loop%2F</url>
    <content type="text"><![CDATA[在利用Tensorflow或CNTK训练DNN的时候，我们可能需要在一次迭代后获得当前的loss或者其他metric。一种常见的方式是：通过一次forward pass计算loss(比如tensorflow的loss.eval())。但是这样带来的额外消耗是没有必要的，因为在训练过程中已经进行过forward pass。 在迭代完成后打印当前的损失值我有一份用CNTK实现的DNN，它的training loop长这样123456789101112131415...ce = C.cross_entropy_with_softmax(z, label_var)pe = C.classification_error(z, label_var)......# training toopfor epoch in range(1, max_epochs+1): sample_count = 0 while sample_count &lt; epoch_size: data = reader_train.next_minibatch(min(minibatch_size, epoch_size - sample_count), input_map=input_map) trainer.train_minibatch(data) sample_count += data[label_var].num_samples trainer.summarize_training_progress()... 但是我希望每完成一个mini batch的训练我都能及时获得当前的loss，因为我希望： 能够在每次迭代后打印当前的loss值 当loss达到某个给定的target_loss的时候就停止训练 一种很自然的想法就是像下面这样：12345678910111213141516...ce = C.cross_entropy_with_softmax(z, label_var)pe = C.classification_error(z, label_var)......# training toopfor epoch in range(1, max_epochs+1): sample_count = 0 while sample_count &lt; epoch_size: data = reader_train.next_minibatch(min(minibatch_size, epoch_size - sample_count), input_map=input_map) trainer.train_minibatch(data)--&gt; curr_loss = np.asscalar(np.mean(ce.eval(data)))--&gt; print("current loss: %f" % (curr_loss)) sample_count += data[label_var].num_samples... 然而我发现这样会拖慢迭代的速度，在加上这两行之前，训练一个256个examples的mini batch大约是13s， 加上后则需要17~18s，显然问题出在curr_loss = np.asscalar(np.mean(ce.eval(data)))这里，进行一次forward pass还是挺耗时的。 正确的方式我们知道在trainer.train_minibatch(data)中是进行过forward pass的，那么看看trainer.train_minibatch()有没有提供这样的接口，从API文档[1]中我们可以看到： 注意红色方框标记的内容。简单地说，反正可以通过传入outputs参数输出制定的令trainer.train_minibatch()以字典的方式返回请求获取的值。最终代码如下：12345678910111213141516171819202122232425262728293031...ce = C.cross_entropy_with_softmax(z, label_var)pe = C.classification_error(z, label_var)......# train loopfinished = Falsefor epoch in range(1, max_epochs+1): if finished: logging.info("Training finished!") break sample_count = 0 batch_cnt = 1 while sample_count &lt; epoch_size: batch_begin_time = time.time() data = reader_train.next_minibatch(min(minibatch_size, epoch_size - sample_count), input_map=input_map)--&gt; _, dict_out = trainer.train_minibatch(data, outputs=[ce, pe])--&gt; curr_loss = np.asscalar(np.mean(dict_out[ce]))--&gt; curr_err_rate = np.asscalar(np.mean(dict_out[pe])) logging.info("epoch[%d of %d] - batch[%d] - training loss=%f - training err_rate = %f %% - %f exampls/s"% (epoch, max_epochs, batch_cnt, curr_loss, curr_err_rate*100, data[label_var].num_samples/(time.time()-batch_begin_time) ) ) sample_count += data[label_var].num_samples batch_cnt += 1 if curr_loss &lt; target_loss: finished = True break... 这样更改之后，我实现了打印loss和用loss控制训练结束，并且训练速度恢复到了约13 s/batch。 注意 : outputs参数需要传入一个iterable的对象，因此即使你只希望取loss一个值，也应该使用trainer.train_minibatch(data, outputs=[loss])而不是trainer.train_minibatch(data, outputs=loss) Tensorflow中该如何做同样的问题，在tensorflow中你应该使用[2] 123456for i in range(100): batch_xs, batch_ys = mnist.train.next_batch(100) cross_entropy = -tf.reduce_sum(y_ * tf.log(y)) _, loss_val = sess.run([train_step, cross_entropy], feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;) print 'loss = ' + loss_val 而不是1234567for i in range(100): batch_xs, batch_ys = mnist.train.next_batch(100) cross_entropy = -tf.reduce_sum(y_ * tf.log(y)) sess.run(train_step, feed_dict=&#123;x: batch_xs, y_: batch_ys&#125;) loss_val = sess.run(cross_entropy) print 'loss = ' + loss_val 下面的例子可以看出两种方式运行时间的差别 参考[1]https://www.cntk.ai/pythondocs/cntk.train.trainer.html [2] https://stackoverflow.com/questions/33833818/printing-the-loss-during-tensorflow-training]]></content>
      <categories>
        <category>人生经验</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Train Alexnet on imagenet-8 using CNTK]]></title>
    <url>%2F2018%2F08%2F19%2FTrain-alexnet-on-imagenet-8-using-CNTK%2F</url>
    <content type="text"><![CDATA[为了做某个与项目有关的评测，我需要在imagenet-8（imagenet的一个子集，只包含前八类的训练数据和测试数据）上用CNTK训练Alexnet。官方提供了Alexnet基于CNTK的python实现，但是却无法直接执行，因为脚本需要数据集中包含一个叫map file的东西。 问题在开始训练前，我已经准备好了imagenet8训练集放在~/dataset/目录下,目录结构如下1234567891011121314151617181920212223242526272829leizhu@pc-office:~/dataset$ tree -d.└── imagenet8 ├── mxnet-format │ ├── train │ ├── train_meta │ ├── val │ └── val_meta └── raw ├── train │ ├── n01440764 │ ├── n01443537 │ ├── n01484850 │ ├── n01491361 │ ├── n01494475 │ ├── n01496331 │ ├── n01498041 │ └── n01514668 └── validation ├── n01440764 ├── n01443537 ├── n01484850 ├── n01491361 ├── n01494475 ├── n01496331 ├── n01498041 └── n0151466825 directories 然后我从CNTK的github仓库中下载了Alexnet的Python实现[1]，并执行该脚本：1python AlexNet_ImageNet_Distributed.py --datadir ~/dataset/imagenet8/raw/ 结果报错1RuntimeError: File &apos;/home/leizhu/dataset/imagenet8/raw/train_map.txt&apos; does not exist. 那么train_map.txt是什么呢？几经周折找到一个实例文件[2]，它长这个样子：12345678val1024.zip@/ILSVRC2012_val_00000001.JPEG 65val1024.zip@/ILSVRC2012_val_00000002.JPEG 970val1024.zip@/ILSVRC2012_val_00000003.JPEG 230val1024.zip@/ILSVRC2012_val_00000004.JPEG 809val1024.zip@/ILSVRC2012_val_00000005.JPEG 516val1024.zip@/ILSVRC2012_val_00000006.JPEG 57val1024.zip@/ILSVRC2012_val_00000007.JPEG 334val1024.zip@/ILSVRC2012_val_00000008.JPEG 415 看起来每一行都是&lt;图象路径&gt; + &lt;标签&gt;。根据链接[3]中的代码，应该就是了。 解决方案编写下面的python脚本1234567891011121314151617181920212223242526272829303132import osimport argparsedef generate_map_file(abs_data_dir): train_dir = os.path.join(abs_data_dir, "train") val_dir = os.path.join(abs_data_dir, "validation") class_dirs = os.listdir(train_dir) with open(os.path.join(abs_data_dir, "train_map.txt"), "w") as f: for i in range(len(class_dirs)): pic_dirname = os.path.join(train_dir, class_dirs[i]) for pic in os.scandir(pic_dirname): if pic.is_file() and pic.name.endswith('.JPEG'): f.write("%s\t%d\n"%(os.path.join(pic_dirname,pic),i)) with open(os.path.join(abs_data_dir, "val_map.txt"), "w") as f: for i in range(len(class_dirs)): pic_dirname = os.path.join(val_dir, class_dirs[i]) for pic in os.scandir(pic_dirname): if pic.is_file() and pic.name.endswith('.JPEG'): f.write("%s\t%d\n"%(os.path.join(pic_dirname,pic),i)) print("generate mapfile successfully!\n")if __name__ == "__main__": parser = argparse.ArgumentParser(description = "generate mapfile") parser.add_argument("--data_dir", type=str, default="/home/leizhu/dataset/imagenet8/raw/", help="absolute path of data directory") args = parser.parse_args() generate_map_file(args.data_dir) 然后执行1python map_file.py --data_dir ~/dataset/imagenet8/raw 再进行训练就没有问题了。 如果你要根据元文件(应该是个xml?我没有原始数据集，太大了下不动)为原始的imagenet ILSVRC数据集生成map file，请参考这里[4]。 referrence[1]https://github.com/Microsoft/CNTK/blob/master/Examples/Image/Classification/AlexNet/Python/AlexNet_ImageNet_Distributed.py [2]https://github.com/Microsoft/CNTK/blob/master/Tests/EndToEndTests/Image/AlexNet/train_map.txt [3]https://cntk.ai/pythondocs/CNTK_201A_CIFAR-10_DataLoader.html [4]https://github.com/Microsoft/CNTK/issues/2091]]></content>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决error:&ensp; Your local changes to the following files would be overwritten by merge]]></title>
    <url>%2F2018%2F08%2F18%2Fsolve-an-error-caused-by-git-pull%2F</url>
    <content type="text"><![CDATA[本文介绍决执行git pull时，错误error: Your local changes to the following files would be overwritten by merge的产生原因和解决方法。 问题git pull博客源代码仓库的时候发现冲突 123456[Leif@pc90005 blog]$ git pullUpdating f89b7be..01cc068error: Your local changes to the following files would be overwritten by merge: _config.ymlPlease commit your changes or stash them before you merge.Aborting 执行git status检查目录状态显示如下 1234567891011121314151617181920[Leif@pc90005 blog]$ git statusOn branch srcYour branch is behind &apos;origin/src&apos; by 1 commit, and can be fast-forwarded. (use &quot;git pull&quot; to update your local branch)Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: _config.ymlUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) source/_posts/MXNet-alexnet-cifar10.md source/_posts/MXNet-stop-training-by-loss.md source/_posts/git-submodule.md source/_posts/ssh-collection.mdno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 原因从上面的结果来看，是因为我修改了_config.yml，导致该文件和服务器上最新的版本不同导致的合并冲突。此时如果git将服务器上的_config.yml（为了区分，记为_config.yml[remote]）拉下来直接覆盖本地文件（记为_config.yml[local]），那么_config.yml[local]中所做的更改就再也找不回来了，这是因为_config.yml[local]还没有commit。git不会擅做这种主张，导致你没有后悔药吃。 解决方案checkout:丢弃本地所做的更改1git checkout HEAD _config.yml 此时执行git pull， git发现当前工作区是干净的，就放心地将_config.yml[remote]下拉回来了。注意，这样的话，你等于主动丢弃_config.yml[local]中所做的更改，这些更改无法恢复。 commit: 将修改提交到仓库1git commit -a -m &quot;modified _config.yml&quot; 同样地，这时工作区是干净的，所以git pull也没有问题。因为已经提交到仓库，你总是有办法找回_config.yml[local]。 stash: 将当前的工作目录另存到储藏栈上如果你不想丢失_config.yml[local]又不想因为这么一点小小的改动就创建一次commit（比如，你希望至少完成一篇博客才做一次提交），那么可以使用git stash。按序执行以下三条命令可以让你将_config.yml[remote]下拉回来，然后和_config.yml[local]合并 123git stashgit pullgit stash pop 关于stash的功能和用法可以参考[1]。简单来说，git stash会 先将你当前的工作目录暂存到一个“储藏栈”的栈顶（这个储藏栈和“暂存区”或者“仓库”不是一个地方） 然后恢复到你上次提交完的状态(相当于再执行git reset --hard) 而git stash pop则会 “储藏栈”栈顶的一次暂存和当前工作目录中文件合并 然后删除储藏栈顶的暂存。 参考[1]https://git-scm.com/book/zh/v2/Git-工具-储藏与清理]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Install cntk on Ubuntu 18.04]]></title>
    <url>%2F2018%2F08%2F17%2Finstall-cntk-on-Ubuntu-18-04%2F</url>
    <content type="text"><![CDATA[按照官网教程[1]，用pip安装cntk仅需简单两步，但是在实际操作中，安装完毕后可能会报错。本文对安装过程做简单总结。 CNTK-Python 安装过程顺次执行下列命令1sudo apt install openmpi-bin (cntk用的是mpi而不是parameter server架构？？？)1pip install cntk (如果要安装支持gpu的版本，请将cntk替换为cntk-gpu) 然后用下面的命令检查cntk是否安装成功1python -c &quot;import cntk; print(cntk.__version__)&quot; Troubleshooting找不到libmpi_cxx.so.1或libmpi.so.12运行 python -c &quot;import cntk; print(cntk.__version__)&quot;时可能显示以下错误123456789101112131415161718192021222324leizhu@pc-office:~$ python -c &quot;import cntk; print(cntk.__version__)&quot;Traceback (most recent call last): File &quot;/home/leizhu/anaconda3/lib/python3.6/site-packages/cntk/cntk_py.py&quot;, line 18, in swig_import_helper return importlib.import_module(mname) File &quot;/home/leizhu/anaconda3/lib/python3.6/importlib/__init__.py&quot;, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 994, in _gcd_import File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 971, in _find_and_load File &quot;&lt;frozen importlib._bootstrap&gt;&quot;, line 953, in _find_and_load_unlockedModuleNotFoundError: No module named &apos;cntk._cntk_py&apos;During handling of the above exception, another exception occurred:Traceback (most recent call last): File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt; File &quot;/home/leizhu/anaconda3/lib/python3.6/site-packages/cntk/__init__.py&quot;, line 17, in &lt;module&gt; from . import cntk_py File &quot;/home/leizhu/anaconda3/lib/python3.6/site-packages/cntk/cntk_py.py&quot;, line 21, in &lt;module&gt; _cntk_py = swig_import_helper() File &quot;/home/leizhu/anaconda3/lib/python3.6/site-packages/cntk/cntk_py.py&quot;, line 20, in swig_import_helper return importlib.import_module(&apos;_cntk_py&apos;) File &quot;/home/leizhu/anaconda3/lib/python3.6/importlib/__init__.py&quot;, line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level)ImportError: libmpi_cxx.so.1: cannot open shared object file: No such file or directory 执行下面的命令解决[2]1sudo ln -s /usr/lib/x86_64-linux-gnu/libmpi_cxx.so.20 /usr/lib/x86_64-linux-gnu/libmpi_cxx.so.1 对于找不到libmpi.so.12的情况同上处理1sudo ln -s /usr/lib/x86_64-linux-gnu/libmpi.so.20.10.1 /usr/lib/x86_64-linux-gnu/libmpi.so.12 此时再执行python -c &quot;import cntk; print(cntk.__version__)&quot;应正常输出版本号。 找不到libpng12.so.0和libjasper.so.1后来在试跑Alexnet的时候又遇到了RuntimeError，先是找不到libpng12.so.0 1RuntimeError: Plugin not found: &apos;Cntk.Deserializers.Image-2.5.1.so&apos; (error: libpng12.so.0: cannot open shared object file: No such file or directory) 解决方式如下[3]123wget -q -O /tmp/libpng12.deb http://mirrors.kernel.org/ubuntu/pool/main/libp/libpng/libpng12-0_1.2.54-1ubuntu1_amd64.debsudo dpkg -i /tmp/libpng12.debrm /tmp/libpng12.deb 然后又找不到libjasper.so.11RuntimeError: Plugin not found: &apos;Cntk.Deserializers.Image-2.5.1.so&apos; (error: libjasper.so.1: cannot open shared object file: No such file or directory) 解决方法[4]：123sudo add-apt-repository &quot;deb http://security.ubuntu.com/ubuntu xenial-security main&quot;sudo apt updatesudo apt install libjasper1 libjasper-dev &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;更新&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; BrainScript API 安装及报错处理要使用Brainscript，必须源码安装CNKT。这个太小众了，要不是有特殊需要我才懒得装。下面的介绍从简。 安装方法参考这个页面[5]建议用Manual install方式。 解决libiomp5.so和libmklml_intel.so缺失安装Intel Math Kernel Library (MKL), 参考这里[6](网上一堆说用source /opt/intel/bin/compilervars.sh intel64的，但是只有安装了Intel的编译器才会有/opt/intel/bin/compilervars.sh这个文件，而且安装了也只能解决libiomp5.so的问题。其实直接安装libmklml_intel.so就好。) 参考[1]https://docs.microsoft.com/en-us/cognitive-toolkit/setup-linux-python?tabs=cntkpy251 [2]https://tweaks-tips.blogspot.com/2017/12/microsoft-cntk-libmpi-importerror.html [3]https://github.com/tcoopman/image-webpack-loader/issues/95 [4]https://stackoverflow.com/questions/43484357/opencv-in-ubuntu-17-04/43507858 [5]https://docs.microsoft.com/en-us/cognitive-toolkit/Install-CNTK-BrainScript#manual-install-1 [6]https://software.intel.com/en-us/articles/intel-mkl-dnn-part-1-library-overview-and-installation]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Make software work properly behind proxy]]></title>
    <url>%2F2018%2F08%2F10%2Fmake-software-work-properly-behind-proxy%2F</url>
    <content type="text"><![CDATA[系里的以太网访问互联网必须经过代理。然而我发现如果仅仅设置系统代理，一些命令(apt update, npm等)仍然无法建立连接，而需要单独设置。记录踩坑过程如下。我使用的系统是Ubuntu 18.04 LTS. 系统代理有一些软件（比如Chrome和Firefox, 命令行中的pip）会默认使用系统代理，也就是说，只要你正确设置了系统代理，这部分软件就能正常联网了。 通过图形界面设置前往Settings -&gt; Network -&gt; Network Proxy -&gt; Manual， 然后如下图所示 注意：填写的地址不要包含“http://”或”https://“字段,直接填写域名或ip. (一定要皮一下加上？那好，在命令行下执行”echo $HTTP_PROXY”，看到了什么？在我测试的Ubuntu 18.04下此时仍然可以正常上网，但是一些命令行软件却无法建立互联网连接了) 通过命令行设置当然，你也可以在命令行下修改，也就是HTTPS_PROXY和HTTP_PROXY加入环境变量。但是由于在图形界面添加的代理没有问题，我没有尝试。有点担心这样能否对对图形界面的程序（比如浏览器）生效。 注意：不管是HTTPS_PROXY还是HTTP_PROXY,都应该设置为”http://…”，如果你将HTTPS_PROXY设为”https://…”，有些软件就不能正常使用了，请参考[3]。 关于GUI和命令行设置代理的区别一个非常有趣的现象是，当我通过GUI设置代理之后，尽管在终端中能通过12echo $HTTP_PROXYecho $HTTPS_PROXY 查看代理环境变量，但是却无法在/etc/environment或者/etc/bash.bashrc或者/etc/.bashrc中发现关于这两个环境变量的记录。我原以为通过GUI设置就会将代理变量写入这些文件。[1]中提到： 如果在GUI设置时apply systme wide (我的Ubuntu 18.04没有该选项)，那么环境变量就会写入/etc/environment 和 /etc/apt/apt.conf， 否则代理变量只存放在gsettings database(就是GUI的数据库？)中。 通过在.bashrc添加代理环境变量通过不会对图形界面程序生效。 不默认使用系统代理的软件apt设置完系统代理后，sudo apt install命令可以正常联网安装软件了，奇怪的是sudo apt update 和 sudo apt add-apt-repository均无法建立互联网连接。一个快速的解决方式如下12sudo -E apt install sofware-namesudo -E apt add-apt-repository ppa:xx/yy 关于这么做的原理，可以参考[2]，简单来说，sudo执行命令时默认不会保留当前用户的环境变量，而-E参数使得环境变量得以保留。（那么为啥不加-E参数时, sudo apt install没毛病呢? emmmmm, 我也不知道） 当然也可以在apt内设置代理:123456sudo vim /etc/apt/apt.conf然后在apt.conf中添加下面两行并保存Acquire::http::proxy &quot;http://lgn:pwd@proxy_sever:proxy_port&quot;;Acquire::https::proxy &quot;http://lgn:pwd@proxy_sever:proxy_port&quot;;如果代理服务器不需要账户和密码则不需要lgn:pwd@字段。 git系统代理设置完成后使用git克隆远程github仓库发现没有响应，使用的命令如下：1git clone git@github.com:LeifZhu/LeifZhu.github.io.git 因为这时使用的是ssh协议，穿不透代理。你可以选择换成clone with https，即执行1git clone https://github.com/LeifZhu/LeifZhu.github.io.git 或者参考[4]或者[5]通过https支持ssh协议。以我的使用为例先安装corkscrew1sudo apt install corkscrew 然后修改~/.ssh/config,添加123456Host github.com User git Hostname ssh.github.com Port 443 ProxyCommand /usr/bin/corkscrew proxy.cse.cuhk.edu.hk 8000 %h %p IdentityFile ~/.ssh/id_rsa 总结 在图形界面设置系统代理时不要加上协议头”http://“ 即使设置了系统代理，一些软件也可能需要在软件内再设置代理。如果你发现浏览器能上网而命令行软件不能，那么你应该考虑配置软件内代理，或者对于sudo命令加上-E参数。 无论是HTTP_PROXY,还是HTTPS_PROXY,都应该设置为”http://…” 参考[1]https://askubuntu.com/questions/830796/proxy-config-gui-vs-setting-http-proxy-in-etc-environment [2]https://stackoverflow.com/questions/8633461/how-to-keep-environment-variables-when-using-sudo [3]https://serverfault.com/questions/817680/https-through-an-http-only-proxy [4]https://unix.stackexchange.com/questions/190490/how-to-use-ssh-over-http-or-https [5]https://blog.csdn.net/twilightdream/article/details/78260394]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
</search>
