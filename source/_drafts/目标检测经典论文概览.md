---
title: 目标检测经典论文概览
tags: [deep learning, object detection]
category: [学习一个]
---

这篇博客中，我将介绍关于目标检测的几篇经典论文。我希望可以简明扼要地说明它们的工作流。

## R-CNN
文章全称[Rich feature hierarchies for accurate object detection and semantic segmentation](https://arxiv.org/pdf/1311.2524.pdf)，发表在CVPR 2014上。

### Pipeline
{% asset_img RCNN.png RCNN %}
1. 从输入的图片中选出可能包含物体的候选区域
2. 针对每个候选区域，用CNN提取特征
3. 将CNN提取的特征作为输入，用n个SVM分别判断该特征是否属于类别$i$, $i \in [n]$， 这里n是目标数据集中类别的数量(VOC中是20， ILSVRC2013上是300)

### 几个关键的问题
#### 候选框是如何产生的？
物体的尺寸有大有小，不同的物体可能有重叠，如何选出那些合适的候选框，使得其中主要包含一个物体？显然，穷举法（穷举候选框的大小，然后在图片上滑动选择区域）的复杂度高出天际，根本不可行。因为分类会在后面的步骤中进行，这里我们希望候选框的产生与类别无关，也就是不会对类别产生偏好。
文章中使用的是 **[selective search](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf)** [留坑待填]。

#### 用于提取特征的CNN是如何训练的？
作者先在ImageNet上预训练了Alexnet。在fine tuning时，对于某张图片，将所有在上一步选出的候选框中, 与ground truth框IOU大于0.5的标记为ground truth类别的正例，其余的标记为负例。

#### 为什么不直接使用CNN最后一层的输出而是另外训练SVM做分类器？
作者在附录中指出了这个问题，简单来说，使用SVM效果要好。在附录B中，作者用了一些他们的猜测来解释为什么会出现这种现象(重新训练SVM做分类器效果更好)，此处略过。以我的眼光来看，倒是这里以IOU为标准标记正负例的方法很有借鉴意义。

